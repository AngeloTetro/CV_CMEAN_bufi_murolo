{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12131200,"sourceType":"datasetVersion","datasetId":7639360},{"sourceId":12173051,"sourceType":"datasetVersion","datasetId":7666763}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Installazione pacchetti (da eseguire solo la prima volta)\n!pip install -q git+https://github.com/huggingface/transformers\n!pip install -q qwen-omni-utils -U\n!pip install -q bitsandbytes -U\n!pip install -q accelerate\n!pip install -q pandas # pandas for CSV operations, though not strictly needed here for basic csv\n\n# Import\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\nimport torch\nimport re\nimport gc\nimport csv\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel_name = \"Qwen/Qwen3-4B\"\n# --- Preparazione della lista dei prompt dal CSV ---\n# Percorso del file CSV\ncsv_file = \"/kaggle/input/qwennn/analisi_audio_intera_cartella_con_features (7).csv\" #\n# Lista per contenere tutti i prompt generati\nprompt_list = []\n# Lista per salvare i dati per il CSV dei risultati finali\nresults_for_csv = []\n\n# Dizionario temporaneo per raggruppare le descrizioni per canzone\ncurrent_song_data = {}\n\ntry:\n    with open(csv_file, newline='', encoding='utf-8') as f:\n        reader = csv.reader(f)\n        header = next(reader)  # Skip header\n\n        for row in reader: #\n            song_name_cell = row[0].strip() # Nome Canzone\n            description_text = row[4].strip() # Colonna 'Descrizione' (indice 4 basato sull'immagine bf21ef.png)\n            description_type = row[3].strip() # Colonna 'Tipo Descrizione' (indice 3)\n\n            # Se la cella Nome Canzone non è vuota, significa che è l'inizio di una nuova canzone\n            if song_name_cell:\n                # Se c'era una canzone precedente da elaborare, la aggiungiamo alla prompt_list\n                if current_song_data:\n                    # Assicurati di avere esattamente 6 descrizioni\n                    # Dovresti decidere l'ordine (es. prima i frammenti, poi il totale)\n                    # Qui assumo che le descrizioni vengano raccolte nell'ordine in cui appaiono nel CSV\n                    # e che la \"Descrizione Totale\" sia l'ultima.\n                    ordered_descriptions = []\n                    # Raccogli i frammenti\n                    for i in range(1, 6): # Assumendo Frammento 1 a 5, come da immagine cc456f.png\n                        ordered_descriptions.append(current_song_data.get(f'Frammento {i}', ''))\n                    \n                    # Raccogli la descrizione totale\n                    overall_desc_found = False\n                    for desc_type_key in ['Totale', 'Descrizione Totale', 'Overall Description']: # Controlla vari nomi possibili\n                        if desc_type_key in current_song_data:\n                            ordered_descriptions.append(current_song_data[desc_type_key])\n                            overall_desc_found = True\n                            break\n                    if not overall_desc_found:\n                        ordered_descriptions.append('') # Aggiungi una stringa vuota se la descrizione totale manca\n\n                    # Rimuovi eventuali stringhe vuote in eccesso se ci sono meno di 6 descrizioni\n                    ordered_descriptions = [d for d in ordered_descriptions if d.strip()]\n                    while len(ordered_descriptions) < 6:\n                        ordered_descriptions.append('') # Assicurati che ci siano sempre 6 descrizioni\n\n                    # Ora genera il prompt per la canzone precedente\n                    prompt = f\"Nome Canzone: {current_song_data['Nome Canzone']}\\n\\n\"\n                    prompt += \"Dati questi frammenti descrittivi di una canzone, valuta su una scala da 0 a 255 quanto ciascuno dei seguenti stati emotivi è evocato dalla descrizione:\\n\"\n                    prompt += \"agitazione/movimento (R), calma (G), tristezza (B).\\n\\n\"\n                    prompt += \"Restituisci **ESATTAMENTE 6 triple RGB COMPLETE**, una dopo l'altra, su una SINGOLA riga. \\n\"\n                    prompt += \"Non includere nessuna spiegazione, numerazione, elenchi puntati o altro testo aggiuntivo. Non usare la modalità di pensiero ('thinking mode').\\n\"\n                    prompt += \"Inizia la riga con 'RGB:' e poi le 6 triple. Ogni tripla deve contenere esattamente tre valori separati da virgole.\\n\\n\"\n                    prompt += \"Ecco l'ESEMPIO ESATTO del formato desiderato (solo 6 triple complete, su una riga):\\n\"\n                    prompt += \"RGB: (R1, G1, B1) (R2, G2, B2) (R3, G3, B3) (R4, G4, B4) (R5, G5, B5) (R6, G6, B6)\\n\\n\"\n                    prompt += \"Ecco i frammenti:\\n\"\n\n                    ordered_prompts_content = []\n                    # Mappa il tipo di descrizione all'etichetta desiderata e un ordine numerico\n                    desc_order = {f'Frammento {j}': j for j in range(1, 6)} # Da Frammento 1 a Frammento 5\n                    desc_order['Totale'] = 6 # La descrizione totale è l'ultima\n\n                    temp_descs = []\n                    for k, v in current_song_data.items():\n                        if k in desc_order:\n                            temp_descs.append({'type': k, 'content': v, 'order': desc_order[k]})\n                    temp_descs.sort(key=lambda x: x['order'])\n\n                    for d in temp_descs:\n                        label = d['type']\n                        if label == 'Totale':\n                            label = \"Descrizione Totale\"\n                        ordered_prompts_content.append(f\"- {label}: {d['content']}\\n\")\n\n                    prompt += \"\".join(ordered_prompts_content)\n\n                    prompt_list.append({'song_name': current_song_data['Nome Canzone'], 'prompt_text': prompt})\n                \n                # Inizia una nuova canzone\n                current_song_data = {\n                    'Nome Canzone': song_name_cell\n                }\n            \n            # Aggiungi la descrizione al dizionario della canzone corrente\n            current_song_data[description_type] = description_text #\n\n        # Non dimenticare di aggiungere l'ultima canzone dopo la fine del loop\n        if current_song_data:\n            ordered_descriptions = []\n            for i in range(1, 6): # Frammento 1 a 5\n                ordered_descriptions.append(current_song_data.get(f'Frammento {i}', ''))\n            \n            overall_desc_found = False\n            for desc_type_key in ['Totale', 'Descrizione Totale', 'Overall Description']:\n                if desc_type_key in current_song_data:\n                    ordered_descriptions.append(current_song_data[desc_type_key])\n                    overall_desc_found = True\n                    break\n            if not overall_desc_found:\n                ordered_descriptions.append('')\n\n            # Assicurati che ci siano esattamente 6 descrizioni, aggiungendo stringhe vuote se necessario\n            ordered_descriptions = [d for d in ordered_descriptions if d.strip()] # Pulisci prima\n            while len(ordered_descriptions) < 6:\n                ordered_descriptions.append('')\n\n            prompt = f\"Nome Canzone: {current_song_data['Nome Canzone']}\\n\\n\"\n            prompt += \"Dati questi frammenti descrittivi di una canzone, valuta su una scala da 0 a 255 quanto ciascuno dei seguenti stati emotivi è evocato dalla descrizione:\\n\"\n            prompt += \"agitazione/movimento (R), calma (G), tristezza (B).\\n\\n\"\n            prompt += \"Restituisci **ESATTAMENTE 6 triple RGB COMPLETE**, una dopo l'altra, su una SINGOLA riga. \\n\"\n            prompt += \"Non includere nessuna spiegazione, numerazione, elenchi puntati o altro testo aggiuntivo. Non usare la modalità di pensiero ('thinking mode').\\n\"\n            prompt += \"Inizia la riga con 'RGB:' e poi le 6 triple. Ogni tripla deve contenere esattamente tre valori separati da virgole.\\n\\n\"\n            prompt += \"Ecco l'ESEMPIO ESATTO del formato desiderato (solo 6 triple complete, su una riga):\\n\"\n            prompt += \"RGB: (R1, G1, B1) (R2, G2, B2) (R3, G3, B3) (R4, G4, B4) (R5, G5, B5) (R6, G6, B6)\\n\\n\"\n            prompt += \"Ecco i frammenti:\\n\"\n\n            ordered_prompts_content = []\n            desc_order = {f'Frammento {j}': j for j in range(1, 6)}\n            desc_order['Totale'] = 6 \n\n            temp_descs = []\n            for k, v in current_song_data.items():\n                if k in desc_order:\n                    temp_descs.append({'type': k, 'content': v, 'order': desc_order[k]})\n            temp_descs.sort(key=lambda x: x['order'])\n\n            for d in temp_descs:\n                label = d['type']\n                if label == 'Totale':\n                    label = \"Descrizione Totale\"\n                ordered_prompts_content.append(f\"- {label}: {d['content']}\\n\")\n\n            prompt += \"\".join(ordered_prompts_content)\n\n            prompt_list.append({'song_name': current_song_data['Nome Canzone'], 'prompt_text': prompt})\n\nexcept FileNotFoundError:\n    print(f\"Errore: Il file CSV '{csv_file}' non è stato trovato.\")\n    print(\"Assicurati che il file si trovi nel percorso specificato.\")\n    exit()\n\n# --- Fine preparazione della lista dei prompt ---\n\n\n# Parametri modello\n\ncompute_dtype = torch.float16\n\n# Configurazione quantizzazione 4-bit\nquant_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_compute_dtype=compute_dtype\n)\n\n# Caricamento tokenizer e modello\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    trust_remote_code=True,\n    quantization_config=quant_config,\n    device_map=\"auto\",\n    low_cpu_mem_usage=True,\n    torch_dtype=compute_dtype\n)\n\n# Loop sui prompt\nfor idx, entry in enumerate(prompt_list, start=1):\n    song_name = entry['song_name']\n    prompt_text = entry['prompt_text']\n\n    print(f\"\\n=== Elaborazione canzone {idx}: {song_name} ===\\n\")\n\n    chat = [{\"role\": \"user\", \"content\": prompt_text}]\n    chat_text = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True, enable_thinking=False)\n\n    inputs = tokenizer(chat_text, return_tensors=\"pt\", truncation=True, max_length=2048)\n    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n\n    outputs = model.generate(\n        **inputs,\n        max_new_tokens=256,\n        do_sample=False,\n        temperature=0.1,\n        num_return_sequences=1,\n    )\n\n    response_text = tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True).strip()\n    print(\"Risposta generata dal modello:\\n\")\n    print(response_text)\n\n    # --- MODIFICA REGEX ---\n    # Questa espressione regolare cerca qualsiasi sequenza di (numero, numero, numero)\n    # catturando i tre numeri.\n    rgb_value_pattern = re.compile(r\"\\((\\d{1,3}),\\s*(\\d{1,3}),\\s*(\\d{1,3})\\)\")\n    found_rgb_matches = rgb_value_pattern.findall(response_text)\n    # --- FINE MODIFICA ---\n\n    current_song_rgb_values = [song_name] # Inizia con il nome della canzone\n\n    # Popola fino a 6 valori RGB. Se ne trova meno, i rimanenti saranno (0,0,0).\n    for i in range(6): # Ci aspettiamo esattamente 6 RGB\n        if i < len(found_rgb_matches):\n            try:\n                # Accedi ai gruppi catturati direttamente dalla tupla\n                r, g, b = int(found_rgb_matches[i][0]), int(found_rgb_matches[i][1]), int(found_rgb_matches[i][2])\n                r, g, b = max(0, min(255, r)), max(0, min(255, g)), max(0, min(255, b))\n                current_song_rgb_values.append(f\"rgb({r}, {g}, {b})\")\n            except ValueError:\n                # Questo gestirà anche casi come (200) dove manca il resto dei numeri\n                print(f\"Errore nel parsing RGB per il match {found_rgb_matches[i] if i < len(found_rgb_matches) else 'inatteso'}. Usando nero.\")\n                current_song_rgb_values.append(\"rgb(0, 0, 0)\")\n        else:\n            # Se non trova abbastanza RGB, aggiunge il nero\n            current_song_rgb_values.append(\"rgb(0, 0, 0)\")\n            print(f\"Avviso: Meno di 6 triple RGB complete trovate per {song_name}. Aggiungendo nero per il frammento {i+1}.\")\n\n    results_for_csv.append(current_song_rgb_values)\n\n    # Pulisci la memoria GPU e CPU dopo ogni elaborazione\n    del inputs, outputs # <--- 'outputs' è definito qui, all'interno del loop\n    torch.cuda.empty_cache()\n    torch.cuda.ipc_collect()\n    gc.collect()\n\n# --- Salvataggio finale dei dati ---\n\n# Saving RGBs only to a separate CSV file\nprint(\"\\n--- Salvataggio dei colori RGB in CSV ---\")\noutput_csv_file = \"valutazione_rgb_segmenti.csv\"\ncsv_header = ['Nome Canzone', 'Frammento 1', 'Frammento 2', 'Frammento 3', 'Frammento 4', 'Frammento 5', 'Descrizione Totale']\n\nwith open(output_csv_file, mode='w', newline='', encoding='utf-8') as f:\n    writer = csv.writer(f)\n    writer.writerow(csv_header)\n    writer.writerows(results_for_csv)\nprint(f\"Colori RGB salvati in '{output_csv_file}'\")\n\nprint(\"\\nProcessing complete. No visualizations or JSON output were generated as per your request.\")\nprint(\"The RGB values are saved in the CSV file.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T12:32:31.303386Z","iopub.execute_input":"2025-06-15T12:32:31.303910Z"}},"outputs":[{"name":"stdout","text":"  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.3/35.3 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/9.73k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57b25a43d1e34b66aaf467359f15e595"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9116750f89544f4687fc1f1d0744f226"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"882380cb3a5b465790af05eb2e6c40ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f30e22dd6b745c6940612cd0ba4d0eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/726 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a7ce8068da34dd2ba06e626b18d0ec1"}},"metadata":{}},{"name":"stderr","text":"2025-06-15 12:34:43.283834: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749990883.462257      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749990883.510374      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/32.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"315ceb36b81a454384b67570475d8224"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f6eaf00095f4f4a8931fdcc31d114be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/99.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ce4e7ab2df541e68894bdac8a1cad37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/3.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3f518596f14461eb4d5f4604846c199"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/3.96G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e8b61da88df4e5a8017fdabeb508744"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3957b73e8bc74e209b4de762daade5a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff08dd0007294eb8ad2e1c240c70892d"}},"metadata":{}},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"\n=== Elaborazione canzone 1: 000002.mp3 ===\n\nRisposta generata dal modello:\n\nRGB: (170, 100, 50) (220, 180, 100) (180, 180, 100) (200, 150, 80) (210, 160, 90) (190, 140, 70)\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"\n=== Elaborazione canzone 2: 000005.mp3 ===\n\nRisposta generata dal modello:\n\nRGB: (255, 100, 30) (255, 100, 30) (255, 100, 30) (255, 100, 30) (255, 100, 30) (255, 100, 30)\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"\n=== Elaborazione canzone 3: 000010.mp3 ===\n\nRisposta generata dal modello:\n\nRGB: (255, 128, 32) (128, 255, 64) (128, 128, 128) (128, 128, 255) (255, 255, 128) (255, 128, 128)\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"\n=== Elaborazione canzone 4: 000140.mp3 ===\n\nRisposta generata dal modello:\n\nRGB: (170, 200, 100) (180, 210, 90) (120, 150, 120) (50, 100, 150) (100, 150, 100) (150, 180, 120)\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"\n=== Elaborazione canzone 5: 000141.mp3 ===\n\nRisposta generata dal modello:\n\nRGB: (120, 160, 180) (100, 130, 150) (140, 170, 160) (130, 160, 150) (140, 170, 160) (120, 160, 180)\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"\n=== Elaborazione canzone 6: 000148.mp3 ===\n\nRisposta generata dal modello:\n\nRGB: (170, 30, 30) (200, 30, 30) (200, 30, 30) (100, 150, 30) (100, 150, 30) (100, 150, 30)\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"\n=== Elaborazione canzone 7: 000182.mp3 ===\n\nRisposta generata dal modello:\n\nRGB: (255, 100, 30) (255, 150, 30) (255, 180, 30) (255, 190, 30) (255, 200, 30) (255, 210, 30)\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"\n=== Elaborazione canzone 8: 000190.mp3 ===\n\nRisposta generata dal modello:\n\nRGB: (170, 200, 100) (180, 210, 90) (160, 200, 95) (175, 215, 85) (165, 205, 90) (170, 205, 95)\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"\n=== Elaborazione canzone 9: 000193.mp3 ===\n\nRisposta generata dal modello:\n\nRGB: (120, 180, 60) (150, 170, 50) (130, 160, 55) (140, 175, 55) (125, 165, 50) (110, 160, 45)\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"\n=== Elaborazione canzone 10: 000194.mp3 ===\n\nRisposta generata dal modello:\n\nRGB: (170, 190, 180) (180, 170, 160) (160, 180, 170) (150, 140, 130) (140, 150, 140) (130, 140, 130)\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"\n=== Elaborazione canzone 11: 000197.mp3 ===\n\nRisposta generata dal modello:\n\nRGB: (120, 180, 60) (140, 160, 50) (130, 170, 55) (125, 165, 55) (135, 175, 50) (128, 172, 52)\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"\n=== Elaborazione canzone 12: 000200.mp3 ===\n\nRisposta generata dal modello:\n\nRGB: (120, 180, 60) (140, 160, 50) (100, 150, 70) (80, 130, 60) (120, 160, 50) (110, 150, 60)\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"\n=== Elaborazione canzone 13: 000203.mp3 ===\n\nRisposta generata dal modello:\n\nRGB: (120, 180, 60) (140, 170, 50) (130, 175, 55) (110, 185, 45) (125, 178, 52) (135, 172, 58)\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"\n=== Elaborazione canzone 14: 000204.mp3 ===\n\nRisposta generata dal modello:\n\nRGB: (120, 180, 60) (50, 80, 100) (140, 160, 80) (70, 110, 50) (130, 150, 60) (110, 140, 50)\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"\n=== Elaborazione canzone 15: 000207.mp3 ===\n\nRisposta generata dal modello:\n\nRGB: (10, 10, 10) (15, 20, 15) (120, 180, 120) (30, 10, 30) (50, 150, 50) (10, 10, 10)\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"\n=== Elaborazione canzone 16: 000210.mp3 ===\n\nRisposta generata dal modello:\n\nRGB: (120, 180, 60) (140, 160, 50) (130, 170, 55) (100, 160, 40) (110, 170, 45) (125, 165, 50)\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"\n=== Elaborazione canzone 17: 000211.mp3 ===\n\nRisposta generata dal modello:\n\nRGB: (120, 180, 60) (120, 180, 60) (120, 180, 60) (120, 180, 60) (120, 180, 60) (120, 180, 60)\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"\n=== Elaborazione canzone 18: 000212.mp3 ===\n\nRisposta generata dal modello:\n\nRGB: (170, 200, 100) (120, 180, 80) (150, 190, 90) (140, 185, 85) (160, 195, 95) (155, 190, 90)\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"\n=== Elaborazione canzone 19: 000213.mp3 ===\n\nRisposta generata dal modello:\n\nRGB: (100, 150, 50) (120, 180, 60) (70, 130, 100) (140, 160, 80) (110, 170, 50) (130, 160, 60)\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"\n=== Elaborazione canzone 20: 000255.mp3 ===\n\nRisposta generata dal modello:\n\nRGB: (255, 100, 30) (255, 150, 30) (128, 128, 128) (255, 180, 30) (255, 120, 30) (255, 140, 30)\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"\n=== Elaborazione canzone 21: 000256.mp3 ===\n\nRisposta generata dal modello:\n\nRGB: (255, 30, 30) (255, 30, 30) (255, 30, 30) (255, 30, 30) (255, 30, 30) (255, 30, 30)\n","output_type":"stream"},{"name":"stderr","text":"The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","output_type":"stream"},{"name":"stdout","text":"\n=== Elaborazione canzone 22: 000368.mp3 ===\n\n","output_type":"stream"}],"execution_count":null}]}